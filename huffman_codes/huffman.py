from __future__ import annotations
from queue import PriorityQueue as prio_q
from typing import Any
import numpy as np
from sys import getsizeof
from node import Node


class HuffmanCompression:
    """A class that encodes the text data into codes. The most repeated symbol has the lowest bits of encoding while the least repeated symbol is encoded with highest bits. Is a method of data compression.\n Refer to: https://en.wikipedia.org/wiki/Huffman_coding"""

    def __init__(self, data: str) -> None:

        assert len(data) > 1
        assert all(type(x) == str for x in data)
        self._data = data
        self._tree = None
        self.table: dict[str, dict[str, Any]] = {}
        self.decode_table = {}
        self._unique_items: list[str] = list(set(data))
        self._frequencies: list[int] = [data.count(x) for x in self._unique_items]
        self._nodes = [
            Node(freq, data)
            for freq, data in zip(self._frequencies, self._unique_items)
        ]

    def _build_tree(self):
        """Internal function. Builds the tree using a priority queue(https://docs.python.org/3/library/queue.html#queue.PriorityQueue). The elements with lowest frequencies are popped first."""
        self.sorted_nodes = prio_q(maxsize=len(self._nodes))
        for node in self._nodes:
            self.sorted_nodes.put_nowait(node)

        while self.sorted_nodes.qsize() > 1:
            lelem = self.sorted_nodes.get_nowait()
            relem = self.sorted_nodes.get_nowait()
            merged_elem = Node(frequency=lelem.frequency + relem.frequency)
            merged_elem.set_left(lelem)
            merged_elem.set_right(relem)
            self.sorted_nodes.put_nowait(merged_elem)
        self._tree = self.sorted_nodes.get_nowait()

    def _generate_codes(self, tree, encoding=""):
        """Internal function. Generates the Huffman codes using by traversing the Huffman tree. The most repeated symbol gets code with least number of bits.

        Args:
            tree (Node): A tree which is generated from the build_tree function.
            encoding (str, optional): Encoding of a symbol. Generated by traversing the tree. If the traversal direction is to left, 0 is appended if the direction is right, 1 is appended. Starts with "".
        """
        if tree is not None:
            if tree.data is not None:
                self.table[tree.data] = {"Frequency": tree.frequency, "Code": encoding}
                self.decode_table[encoding] = tree.data
            left_encoding = encoding + "0"
            right_encoding = encoding + "1"
            self._generate_codes(tree.get_left, encoding=left_encoding)
            self._generate_codes(tree.get_right, encoding=right_encoding)

    def compress(self, chunk_length: int = 100):
        """Performs data compression with Huffman codes.

        Args:
            chunk_length (int, optional): Chunks of the compressed binary codes which are converted to decimal format. Defaults to 100.

        Returns:
            decoder_table (dict[str, str]): A table which consists of codes and the respective symbols.
            chunks (list[list[int]]): Chunks of the encoded data.
        """
        self._build_tree()
        self._generate_codes(tree=self._tree)

        self.encoding = "".join([self.table[char]["Code"] for char in self._data])

        chunks = [
            [
                int(self.encoding[pos : pos + chunk_length], 2),
                len(self.encoding[pos : pos + chunk_length]),
            ]
            for pos in range(0, len(self.encoding), chunk_length)
        ]

        return self.decode_table, chunks

    def get_stats(self):
        """Returns statistics of Huffman code operation on given data.

        Returns:
            dictionary(str, float): Returns Entropy and Weighted lengths of the encoding.
        """
        # symbol = list(self.table.keys())
        sum_freq = sum(self._frequencies)
        weights = [
            self.table[data]["Frequency"] / sum_freq for data in self.table.keys()
        ]
        assert sum(weights) == 1

        codewords = [self.table[data]["Code"] for data in self.table.keys()]
        codewords_len = list(map(lambda x: len(x), codewords))

        contrib_weighted_path_len = np.dot(weights, codewords_len)

        probability_budget = np.pow(1 / 2, codewords_len)
        information_content = np.negative(np.log2(weights))
        contrib_entropy = np.dot(probability_budget, information_content)
        efficiency = contrib_entropy / contrib_weighted_path_len

        return {"H": contrib_entropy, "L": contrib_weighted_path_len}


def retrieve_binary(encoded_list: list[list[int]]):
    """From the encoded list, recreate binary representation of the data.

    Args:
        encoded_list (list[ list[ int]]): List of lists. The lists have 2 elements, (Decimal value, chunk length). Chuck length is needed as the last chunk might have lower length than the other chunks.\nAlso, when decoding binary from decimal, at times values are lost due to the binary chunk starting with zeros.

    Returns:
        binary_encoding(str): A single binary string of 0s and 1s.
    """
    binary_encoding = "".join([bin(x[0])[2:].zfill(x[1]) for x in encoded_list])

    return binary_encoding


def retrieve_data(binary_encoding, decode_table: dict[str, str]):
    """Recreates the input data from the binary encoding and decoder table.

    Args:
        binary_encoding (str): A single binary string recreated from the compressed data.
        decode_table (dict[str, str]): A reference table to decode the single binary string.

    Returns:
        decoded_text(str): Text recreated from compressed data. Should be same as input text.
    """
    decoded_text = ""
    curr_val = ""
    min_len = len(
        min(decode_table.keys(), key=lambda x: len(x))
    )  # smallest length of the encoded symbol.
    for binary_val in binary_encoding:
        curr_val += binary_val
        if len(curr_val) >= min_len:
            if curr_val in decode_table.keys():  # If the chunck is found in the table
                decoded_text += decode_table[
                    curr_val
                ]  # Append the text with the value.
                curr_val = ""
    return decoded_text


if __name__ == "__main__":

    # data = """God, grant me the serenity to accept the \
    #     things I cannot change, the courage to change the things I can,\
    #         and the wisdom to know the difference."""

    with open("./moby_dick.txt", "r") as file:
        data = " ".join(file.readlines())

    ### ENCODING --> Encode the text read from the file into chunks. And simultaneously generate a decoder table. Emulates the process of encoding and compressing the data.
    huffman_pipeline = HuffmanCompression(data)
    table, chunks = huffman_pipeline.compress(chunk_length=100)
    # print(f"Encoding: {chunks}\n\n Decoder table: {table}")

    ### DECODING --> Decodes the compressed data (chunks) with the help of decode_table(table). Emulates the process of decoding and extraction of data.
    binary = retrieve_binary(chunks)
    text = retrieve_data(decode_table=table, binary_encoding=binary)

    print(
        f"\n\n---> Original text(variable, data) == Decoded text (variable, text): {data == text}"
    )
    print(
        f"---> Compression rate: {getsizeof(data)/(getsizeof(chunks) + getsizeof(table))}"
    )

    print(
        "\n\n\t\t****** Stats ******\n\n"
        + "Original size : ".rjust(40)
        + f"{getsizeof(data)} bytes".ljust(20)
        + "\n\n"
        + f"Total encoding size : ".rjust(40)
        + f"{getsizeof(chunks) + getsizeof(table)} bytes".ljust(20)
        + "\n"
        + f"With,\tEncoding size : ".rjust(45)
        + f"{getsizeof(chunks)} bytes".ljust(20)
        + "\n     "
        + f"\tDecoding table size : ".rjust(45)
        + f"{getsizeof(table)} bytes".ljust(20)
        + "\n\n\t\t*******************"
    )
